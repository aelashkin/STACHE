env_config:
  env_name: MiniGrid-Empty-Random-6x6-v0
  evaluate_with_modified_reward: false
  max_objects: 10
  max_walls: 32
  render_mode: null
  representation: symbolic
  reward_wrappers:
    action_bonus: true
    position_bonus: false
  total_timesteps: 100000
model_config:
  batch_size: 64
  device: cpu
  ent_coef: 0.01
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.0003
  model_type: PPO
  n_epochs: 10
  n_steps: 128
  normalize_advantage: true
