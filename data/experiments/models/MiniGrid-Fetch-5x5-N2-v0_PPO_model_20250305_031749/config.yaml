env_config:
  env_name: MiniGrid-Fetch-5x5-N2-v0
  evaluate_with_modified_reward: false
  max_objects: 10
  max_walls: 32
  render_mode: null
  representation: symbolic
  reward_wrappers:
    action_bonus: false
    position_bonus: false
  total_timesteps: 100000
model_config:
  batch_size: 64
  device: cpu
  ent_coef: 0.001
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.0003
  model_type: PPO
  n_epochs: 10
  n_steps: 256
  normalize_advantage: true
